import requests
from bs4 import BeautifulSoup
import facebook
import instaloader
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class SocialMediaScraper:
    def __init__(self):
        self.facebook_access_token = "YOUR_FACEBOOK_ACCESS_TOKEN"
        self.instagram_username = "YOUR_INSTAGRAM_USERNAME"
        self.instagram_password = "YOUR_INSTAGRAM_PASSWORD"
        self.tiktok_username = "YOUR_TIKTOK_USERNAME"
        self.triller_username = "YOUR_TRILLER_USERNAME"

    def scrape_facebook(self):
        graph = facebook.GraphAPI(self.facebook_access_token)
        page_data = graph.get_object(id="YOUR_FACEBOOK_PAGE_ID")
        print(page_data['name'])
        print(page_data['about'])

    def scrape_instagram(self):
        L = instaloader.Instaloader()
        profile = instaloader.Profile.from_username(L.context, self.instagram_username)
        posts = profile.get_posts()
        for post in posts:
            print(post.caption)

    def scrape_tiktok(self):
        url = f"https://www.tiktok.com/{self.tiktok_username}"
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        videos = soup.find_all('div', {'class': 'video-metadata'})
        for video in videos:
            title = video.find('h2').text.strip()
            description = video.find('p').text.strip()
            print(f"Title: {title}")
            print(f"Description: {description}")

    def scrape_triller(self):
        url = f"https://www.triller.co/{self.triller_username}"
        response = requests.get(url)
        soup = BeautifulSoup(response.content, 'html.parser')
        videos = soup.find_all('div', {'class': 'video-metadata'})
        for video in videos:
            title = video.find('h2').text.strip()
            description = video.find('p').text.strip()
            print(f"Title: {title}")
            print(f"Description: {description}")

    def scrape_twitter(self):
        driver = webdriver.Chrome()
        driver.get("https://twitter.com/login")
        username_input = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME, "session[username_or_email]")))
